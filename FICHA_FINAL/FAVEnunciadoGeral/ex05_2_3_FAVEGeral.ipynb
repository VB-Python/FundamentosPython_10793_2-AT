{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''5. Usando as bibliotecas Pandas e MatPlotLib e um dataset (podes selecionar das aulas, fazer \n",
    "download na plataforma kaggle ou escolher um dataset pessoal), elabora um notebook \n",
    "jupyter no qual efetues: \n",
    "•1_3 Limpeza e tratamento de dados; \n",
    "•2_3 Processamento de dados: groupby, filter, criação de novas colunas,…; \n",
    "•3_3 Visualização de dados; \n",
    "    alínea          Cotação (escala 1-20) \n",
    "        1                       3 \n",
    "        2                       4 \n",
    "        3                       4 \n",
    "        4                       4 \n",
    "        5                       5 '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  title  year      name   type                character     n\n",
      "0        Closet Monster  2015  Buffy #1  actor                  Buffy 4  31.0\n",
      "1       Suuri illusioni  1985    Homo $  actor                   Guests  22.0\n",
      "2   Battle of the Sexes  2017   $hutter  actor          Bobby Riggs Fan  10.0\n",
      "3  Secret in Their Eyes  2015   $hutter  actor          2002 Dodger Fan   NaN\n",
      "4            Steve Jobs  2015   $hutter  actor  1988 Opera House Patron   NaN \n",
      "\n",
      "<<<<<>>>>>\n",
      "\n",
      "                          title  year                        name     type  \\\n",
      "74996  Mia fora kai ena... moro  2011     Penelope Anastasopoulou  actress   \n",
      "74997         The Magician King  2004       Tiannah Anastassiades  actress   \n",
      "74998        Festival of Lights  2010             Zoe Anastassiou  actress   \n",
      "74999                Toxic Tutu  2016             Zoe Anastassiou  actress   \n",
      "75000           Fugitive Pieces  2007  Anastassia Anastassopoulou  actress   \n",
      "\n",
      "                     character     n  \n",
      "74996       Popi voulkanizater  11.0  \n",
      "74997  Unicycle Race Attendant   NaN  \n",
      "74998       Guidance Counselor  20.0  \n",
      "74999        Demon of Toxicity   NaN  \n",
      "75000             Laundry Girl  25.0  \n"
     ]
    }
   ],
   "source": [
    "#ler ficheiro cast.csv para dataframe do pandas casts\n",
    "casts = pd.read_csv('cast.csv', index_col=None) \n",
    " \n",
    "#Imprime as 5 primeiras linhas\n",
    "print(casts.head(),\"\\n\\n<<<<<>>>>>\\n\")\n",
    "#Imprime as 5 últimas linhas\n",
    "print(casts.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     title  year\n",
      "0           The Rising Son  1990\n",
      "1  The Thousand Plane Raid  1969\n",
      "2         Crucea de piatra  1993\n",
      "3                  Country  2000\n",
      "4               Gaiking II  2011 \n",
      "\n",
      "<<<<<>>>>>\n",
      "\n",
      "                      title  year\n",
      "49995                 Rebel  1970\n",
      "49996               Suzanne  1996\n",
      "49997                 Bomba  2013\n",
      "49998  Aao Jao Ghar Tumhara  1984\n",
      "49999            Mrs. Munck  1995\n"
     ]
    }
   ],
   "source": [
    "#ler ficheiro titles.csv para dataframe pandas titles \n",
    "titles = pd.read_csv('titles.csv', index_col =None) \n",
    " \n",
    "#Imprime as 5 primeiras linhas\n",
    "print(titles.head(),\"\\n\\n<<<<<>>>>>\\n\")\n",
    "#Imprime as 5 últimas linhas\n",
    "print(titles.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2003    2\n",
      "2004    2\n",
      "2005    2\n",
      "2006    1\n",
      "2007    2\n",
      "dtype: int64 \n",
      "\n",
      "<<<<<>>>>>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "year  title                               \n",
       "2003  The In-Laws                             1\n",
       "      The Visual Bible: The Gospel of John    1\n",
       "2004  Resident Evil: Apocalypse               1\n",
       "      Siblings                                1\n",
       "2005  Cinderella Man                          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = casts  \n",
    " \n",
    "#obtem o dataframe cf a partir de c filtrando os dados que verifiquem a condição do autor ser 'Aaron Abrams' \n",
    "cf = c[c['name'] == 'Aaron Abrams']  \n",
    " \n",
    "#Agrupar os dados do dataframe anterior (autor ser 'Aaron Abrams') pela coluna year (ano), primeiras 5 linhas\n",
    "print(cf.groupby(['year']).size().head(),\"\\n\\n<<<<<>>>>>\\n\") \n",
    " \n",
    "#groupby agrupar por múltiplas colunas, 2 colunas, year e tittle. Mostra as 5 linhas iniciais.\n",
    "gbmultiplecolumns = cf.groupby(['year', 'title']).size() \n",
    "gbmultiplecolumns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    title  year      country        date\n",
      "0   #73, Shaanthi Nivaasa  2007        India  2007-06-15\n",
      "1                 #Beings  2015      Romania  2015-01-29\n",
      "2               #Declimax  2018  Netherlands  2018-01-21\n",
      "3  #Ewankosau saranghaeyo  2015  Philippines  2015-01-21\n",
      "4                 #Horror  2015          USA  2015-11-20 \n",
      "\n",
      "<<<<<>>>>>\n",
      "\n",
      "        title  year            name   type    character     n\n",
      "5767   Amelia  2009    Aaron Abrams  actor  Slim Gordon   8.0\n",
      "23319  Amelia  2009  Jeremy Akerman  actor      Sheriff  19.0 \n",
      "\n",
      "<<<<<>>>>>\n",
      "\n",
      "        title  year    country        date\n",
      "20543  Amelia  1966     Mexico  1966-03-10\n",
      "20544  Amelia  2009     Canada  2009-10-23\n",
      "20545  Amelia  2009        USA  2009-10-23\n",
      "20546  Amelia  2009  Australia  2009-11-12\n",
      "20547  Amelia  2009  Singapore  2009-11-12 \n",
      "\n",
      "<<<<<>>>>>\n",
      "\n",
      "    title  year          name   type    character    n    country        date\n",
      "0  Amelia  2009  Aaron Abrams  actor  Slim Gordon  8.0     Canada  2009-10-23\n",
      "1  Amelia  2009  Aaron Abrams  actor  Slim Gordon  8.0        USA  2009-10-23\n",
      "2  Amelia  2009  Aaron Abrams  actor  Slim Gordon  8.0  Australia  2009-11-12\n",
      "3  Amelia  2009  Aaron Abrams  actor  Slim Gordon  8.0  Singapore  2009-11-12\n",
      "4  Amelia  2009  Aaron Abrams  actor  Slim Gordon  8.0    Ireland  2009-11-13\n"
     ]
    }
   ],
   "source": [
    "# Extra: Exemplo Merge\n",
    "\n",
    "\n",
    "#leitura dos dados do ficheiro release_dates.csv para o dataframe release \n",
    "release = pd.read_csv('release_dates.csv', index_col=None) \n",
    "print(release.head(),\"\\n\\n<<<<<>>>>>\\n\") \n",
    "\n",
    "# filtrar Amelia do cast.csv\n",
    "c_amelia = casts[ casts['title'] == 'Amelia'] \n",
    "print(c_amelia.head(),\"\\n\\n<<<<<>>>>>\\n\") \n",
    "\n",
    "# filtrar Amelia do release_dates.csv\n",
    "print(release [ release['title'] == 'Amelia' ].head(),\"\\n\\n<<<<<>>>>>\\n\") \n",
    " \n",
    "#imprime os primeiras cinco linhas do merge (fusão) c_amelia com o dataframe, junta os 2 resultados\n",
    "release \n",
    "print(c_amelia.merge(release).head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    title  amelia_count\n",
      "0  Amelia             2 \n",
      "\n",
      "<<<<<>>>>>\n",
      "\n",
      "        title  year            name   type    character     n\n",
      "5767   Amelia  2009    Aaron Abrams  actor  Slim Gordon   8.0\n",
      "23319  Amelia  2009  Jeremy Akerman  actor      Sheriff  19.0 \n",
      "\n",
      "<<<<<>>>>>\n",
      "\n",
      "       title  amelia_count\n",
      "5775  Amelia            25\n",
      "    title  amelia_count\n",
      "0  Amelia             2\n"
     ]
    }
   ],
   "source": [
    "# Agrupar os dados de 'c_amelia' por 'title' e contar o número de registros por título\n",
    "c_amelia_grouped = c_amelia.groupby('title').size().reset_index(name='amelia_count')\n",
    "print(c_amelia_grouped.head(), \"\\n\\n<<<<<>>>>>\\n\")\n",
    "#apresentar\n",
    "print(c_amelia.head(),\"\\n\\n<<<<<>>>>>\\n\") \n",
    "\n",
    "# Agora, podemos comparar os dados agrupados de 'release' e 'c_amelia'\n",
    "# Podemos fazer isso com um merge se necessário, mas aqui é só uma comparação com base no título\n",
    "print(release_grouped[release_grouped['title'] == 'Amelia'])\n",
    "print(c_amelia_grouped[c_amelia_grouped['title'] == 'Amelia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Pclass'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\barbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Pclass'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m novas_colunas_pclass = pd.get_dummies(\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPclass\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m      2\u001b[39m novas_colunas_sex = pd.get_dummies(c[\u001b[33m\"\u001b[39m\u001b[33mSex\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      4\u001b[39m c1 = pd.concat([c, novas_colunas_pclass, novas_colunas_sex], axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\barbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\barbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Pclass'"
     ]
    }
   ],
   "source": [
    "novas_colunas_pclass = pd.get_dummies(c[\"Pclass\"])\n",
    "novas_colunas_sex = pd.get_dummies(c[\"Sex\"])\n",
    "\n",
    "c1 = pd.concat([c, novas_colunas_pclass, novas_colunas_sex], axis=1)\n",
    "#c1.drop([\"Pclass\", \"Sex\"], axis=1, inplace=True)\n",
    "print(c.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f163444",
   "metadata": {},
   "source": [
    "\n",
    "# Análise Exploratória de Dados (EAD)\n",
    "\n",
    "Este notebook realiza a análise exploratória de dados (EAD) com base no conjunto de dados fornecido. As principais etapas incluem a importação dos dados, verificação de dados ausentes, verificação de duplicados, análise descritiva, visualizações e conversão de variáveis categóricas.\n",
    "\n",
    "## Passos:\n",
    "\n",
    "1. **Carregar os Dados**: Carregar o conjunto de dados a partir de um arquivo CSV.\n",
    "2. **Verificação de Tipos de Dados**: Verificar os tipos de dados para garantir que as colunas estão corretamente tipadas.\n",
    "3. **Verificação de Valores Ausentes**: Identificar e tratar valores ausentes.\n",
    "4. **Verificação de Duplicados**: Identificar e remover linhas duplicadas.\n",
    "5. **Conversão de Variáveis Categóricas**: Aplicar One-Hot Encoding em variáveis categóricas para transformá-las em variáveis numéricas.\n",
    "6. **Estatísticas Descritivas**: Exibir estatísticas descritivas para variáveis numéricas.\n",
    "7. **Visualizações**: Realizar visualizações para explorar a distribuição de variáveis numéricas e identificar outliers.\n",
    "8. **Correlação entre Variáveis**: Calcular e visualizar a correlação entre variáveis numéricas.\n",
    "9. **Detecção de Outliers**: Identificar e remover outliers utilizando o intervalo interquartil (IQR).\n",
    "10. **Criação de Faixas Etárias**: Criar uma nova variável que classifique os clientes em faixas etárias.\n",
    "11. **Frequências de Compra**: Analisar a distribuição das frequências de compra dos clientes.\n",
    "12. **Relação entre Idade e Valor de Compra**: Explorar a relação entre idade e valor de compra.\n",
    "\n",
    "## Código\n",
    "\n",
    "A seguir está o código associado a cada uma dessas etapas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8517d775",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 88) (2091423482.py, line 88)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 88\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 88)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importação das bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Passo 1: Carregar os Dados\n",
    "# Carregar o arquivo CSV\n",
    "df = pd.read_csv('shopping_trends.csv')\n",
    "\n",
    "# Passo 2: Verificação de Tipos de Dados\n",
    "# Exibir os tipos de dados para garantir que as colunas estão corretamente tipadas\n",
    "print(\"Tipos de dados:\", df.dtypes)\n",
    "\n",
    "# Passo 3: Verificação de Valores Ausentes\n",
    "# Identificar se há valores ausentes em qualquer coluna\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Valores ausentes por coluna:\", missing_values)\n",
    "\n",
    "# Verificar a porcentagem de valores ausentes\n",
    "missing_percentage = (df.isnull().mean() * 100).round(2)\n",
    "print(\"Porcentagem de valores ausentes por coluna:\", missing_percentage)\n",
    "\n",
    "# Passo 4: Verificação de Duplicados\n",
    "# Identificar e remover linhas duplicadas\n",
    "duplicates = df.duplicated().sum()\n",
    "print(\"Número de linhas duplicadas:\", duplicates)\n",
    "\n",
    "# Remover duplicados\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Passo 5: Conversão de Variáveis Categóricas para Variáveis Dummy (One-Hot Encoding)\n",
    "# As colunas 'Gender' e 'Category' são categóricas, então vamos convertê-las para variáveis dummy\n",
    "df = pd.get_dummies(df, columns=['Gender', 'Category'], drop_first=True)\n",
    "\n",
    "# Passo 6: Estatísticas Descritivas\n",
    "# Exibir estatísticas descritivas para variáveis numéricas\n",
    "print(\"Estatísticas descritivas:\", df.describe())\n",
    "\n",
    "# Passo 7: Visualizações - Distribuição de Variáveis Numéricas\n",
    "# Visualizar a distribuição da variável 'Purchase Amount (USD)'\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['Purchase Amount (USD)'].hist(bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribuição do Valor das Compras (USD)')\n",
    "plt.xlabel('Valor da Compra (USD)')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()\n",
    "\n",
    "# Passo 8: Visualizações - Boxplot para Identificar Outliers\n",
    "# Boxplot para a variável 'Purchase Amount (USD)' para identificar outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['Purchase Amount (USD)'], color='orange')\n",
    "plt.title('Boxplot do Valor das Compras (USD)')\n",
    "plt.xlabel('Valor da Compra (USD)')\n",
    "plt.show()\n",
    "\n",
    "# Passo 9: Análise de Correlação entre Variáveis Numéricas\n",
    "# Filtrando apenas as colunas numéricas\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calcular a matriz de correlação para as variáveis numéricas\n",
    "correlation_matrix = numeric_df.corr()\n",
    "print(\"Matriz de Correlação:\", correlation_matrix)\n",
    "\n",
    "# Visualização da Matriz de Correlação com Heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Matriz de Correlação entre Variáveis Numéricas')\n",
    "plt.show()\n",
    "\n",
    "# Passo 10: Verificação de Outliers Usando Intervalo Interquartil (IQR)\n",
    "# Detectar e remover outliers na variável 'Purchase Amount (USD)' utilizando o IQR\n",
    "Q1 = df['Purchase Amount (USD)'].quantile(0.25)\n",
    "Q3 = df['Purchase Amount (USD)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_limit = Q1 - 1.5 * IQR\n",
    "upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remover outliers\n",
    "df = df[(df['Purchase Amount (USD)'] >= lower_limit) & (df['Purchase Amount (USD)'] <= upper_limit)]\n",
    "\n",
    "# Passo 11: Criação de Faixas Etárias (Novo Grupo)\n",
    "# Criar uma nova variável para faixa etária (faixa etária por grupos)\n",
    "bins = [0, 18, 40, 60, 100]\n",
    "labels = ['Jovem', 'Adulto', 'Meia-Idade', 'Idoso']\n",
    "df['Age Group'] = pd.cut(df['Age'], bins=bins, labels=labels)\n",
    "\n",
    "# Visualizar a nova variável 'Age Group'\n",
    "print(\"Distribuição das faixas etárias:\", df['Age Group'].value_counts())\n",
    "\n",
    "# Passo 12: Visualização das Frequências de Compra\n",
    "# Exibir a distribuição das frequências de compra dos clientes\n",
    "purchase_frequency = df['Frequency of Purchases'].value_counts()\n",
    "print(\"Distribuição das Frequências de Compras:\", purchase_frequency)\n",
    "\n",
    "# Gráfico de barras para mostrar a distribuição de frequências de compras\n",
    "plt.figure(figsize=(10, 6))\n",
    "purchase_frequency.plot(kind='bar', color='lightgreen', edgecolor='black')\n",
    "plt.title('Distribuição das Frequências de Compras')\n",
    "plt.xlabel('Frequência de Compras')\n",
    "plt.ylabel('Número de Clientes')\n",
    "plt.show()\n",
    "\n",
    "# Passo 13: Identificação de Relação entre 'Age' e 'Purchase Amount (USD)'\n",
    "# Gráfico de dispersão entre 'Age' e 'Purchase Amount (USD)'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Age'], df['Purchase Amount (USD)'], alpha=0.5, color='blue')\n",
    "plt.title('Relação entre Idade e Valor da Compra (USD)')\n",
    "plt.xlabel('Idade')\n",
    "plt.ylabel('Valor da Compra (USD)')\n",
    "plt.show()\n",
    "\n",
    "# Passo 14: Verificação de Valores Ausentes Após Limpeza\n",
    "# Recalcular valores ausentes após os tratamentos\n",
    "missing_values_after_cleaning = df.isnull().sum()\n",
    "print(\"Valores ausentes após limpeza:\", missing_values_after_cleaning)\n",
    "\n",
    "# Passo 15: Verificação de Duplicados Após Limpeza\n",
    "# Verificar se há duplicados após a remoção\n",
    "duplicates_after_cleaning = df.duplicated().sum()\n",
    "print(\"Número de linhas duplicadas após limpeza:\", duplicates_after_cleaning)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
